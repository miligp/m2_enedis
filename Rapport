# RAPPORT METHODOLOGIQUE

Dans le cadre de notre projet, nous devions cr√©er une interface permettant de pr√©voir et visualiser la consommation √©n√©rg√©tique et l'√©tiquette DPE d'un foyer en se basant sur des informations entr√©es par l'utilisateur. 
Ce rapport reprend les √©tapes principales de notre travail en expliquant, dans les grandes lignes, les m√©thodes et choix effectu√©s, de l'acquisition des donn√©es jusqu'√† leur utilisation dans la conception de nos mod√®les de pr√©diction.

##  1. ACQUISITION ET TRAITEMENT DES DONNEES


L'acquisition des donn√©es s'est faite depuis l'API de l'ADEME sous la forme de deux jeux de donn√©es, l'un contenant des informations sur les logements neufs et l'autre sur des logements anciens.
Ces dataframes n'ayant pas la m√™me structure, des transformations ont √©t√© effectu√©es disctinctement sur chaque dataframe dans un premier temps, elles seront abord√©es superficiellement dans un premier temps.
Une fois les deux dataframes joints pour n'en former qu'un seul, d'autres transformations ont effectu√©es et seront davantage expliqu√©es dans un second temps.

### A. Traitement avant concat√©nation
#### 1. Valeurs manquantes
Dans les deux dataframes, des valeurs manquaient, surtout pour les variables 'complement_adresse_logement', 'annee_construction', 'nombre_appartement' et 'type_installation_chauffage' dans le dataframe contenant les logements anciens et pour 'surface_habitable_immeuble', 'nombre_niveau_logement' dans celui contenant les logements neufs.   

* Les lignes contenant les valeurs manquantes pour la variable 'type_installation_chauffage' ont √©t√© supprim√©es .
* La variable 'complement_adresse_logement' contient beaucoup de valeurs manquantes (22%), n'apportant pas une information n√©cessaire dans ce contexte, elle a √©t√© supprim√©e enti√®rement.
* La variable 'annee_construction' contient elle aussi beaucoup de valeurs manquantes(42%), puisque nous disposons de la variable 'p√©riode_construction', elle a √©t√© supprim√©e.
* Les lignes manquantes pour les variables 'surface_habitable_logement' et 'surface_chauffee_installation_chauffage_n1' ont √©t√© supprim√©es dans le dataframe des anciens logements. Pour √©viter la redondance avec les deux pr√©c√©dentes, la variable 'surface_chauffee_installation_chauffage_n1' a √©t√© supprim√©e.


#### 2. Variables cat√©gorielles complexes
* Dans les deux dataframe, la variable cat√©gorielle 'type_energie_principale__chauffage' contient de trop nombreuses modalit√©s, afin de r√©duire leur nombre elles ont √©t√© regroup√©es parmi celles-ci seulement : Gaz naturel, Electricit√©, R√©seau de chauffage urbain, Bois et biomasse, Fioul, Gaz(GPL/Propane/Butane), Charbon.
* La variable 'type_energie_n1' a √©t√© trait√©e de la m√™me fa√ßon.
* La variable 'configuration_installation_chauffage_n1' contenant beaucoup de modalit√©s elle aussi, et s'av√©rant redondante avec les pr√©c√©dentes variables, a √©t√© supprim√©e afin d'√©viter la multicolin√©arit√© et de r√©duire le risque de surapprentissage par la suite.
* La variable 'type_generateur_chauffage_principal' contient trop modalit√©s, pour les m√™mes raisons que pr√©c√©demment elle a aussi √©t√© supprim√©e.


#### 3. Variables g√©ographiques
La variable geopoint a √©t√© splitt√©e en deux variables : latitude et longitude. 


#### 4. Uniformisation des deux dataframes

* Une colonne 'logement' a √©t√© ajout√©e aux deux dataframes, pour l'un elle contient la valeur 'ancien', pour l'autre la valeur 'neuf'.
* Une colonne 'p√©riode_construction' a aussi √©t√© cr√©√©e dans le dataframe des logements neufs en y ins√©rant la valeur 'apr√®s 2021' pour toutes les lignes.

### B. Traitement apr√®s concat√©nation

Le dataframe obtenu  contient 1152372 lignes et 30 colonnes.

#### 1. Valeurs manquantes

La variable 'nombre_appartement' contient 

#### 2. Encodage des variables ordinales

Les variables 'qualite_isolation_murs', 'etiquette_dpe', 'nombre_appartement_cat', 'periode_construction'ont √©t√© r√©encod√©es √† l'aide d'un dictionnaire dont les cl√©s sont les variables et les valeurs les modalit√©s des variables. A l'aide d'une boucle, chaque modalit√© a √©t√© remplac√©e par la valeur de son index dans se liste de valeurs.

#### 3. Encodage des variables nominales

La variable 'type_batiment' contient trois modalit√©s : 'appartement', 'immeuble' et 'maison'. Les modalit√©s correspondant √† 'immeuble' ont √©t√© ramen√©es sous la modalit√© 'appartement' de fa√ßon √† r√©encoder simplement la variable.

#### 4. Variables quantitatives et valeurs aberrantes

Les variables quantitatives qui seront utilis√©es dans les mod√®les de pr√©diction, sont d√©finies sur des amplitudes importantes du fait de valeurs aberrantes. Les algorithmes utilis√©s dans la cr√©ation des mod√®les √©tant bas√©s sur des calculs de distances, ils sont sensibles √† ces √©carts. Afin de r√©duire ceux-ci, les valeurs aberrantes ont √©t√© supprim√©es.


```python
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd


pd.set_option('display.width', None)

df=pd.read_csv("C:/Users/marvi/Desktop/4_Python_ML/Projet/df_logement.csv", sep = ';')

Quantitatives = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
variables_exclure = ['qualite_isolation_murs', 'etiquette_dpe', 'nombre_appartement_cat']

variables_quantitatives = ['conso_5_usages_ef', 'conso_5_usages_ef_energie_n1', 'cout_total_5_usages', 'hauteur_sous_plafond', 'cout_total_5_usages_energie_n1', 'surface_habitable_logement', 'periode_construction']

import matplotlib.pyplot as plt
import seaborn as sns

# Statistiques descriptives
print("Statistiques des variables quantitatives:")
stats_quanti_avec_outliers = df[variables_quantitatives].describe().round(2).T.drop(columns=['count'])
print(stats_quanti_avec_outliers)

# Visualisation des distributions
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.ravel()

for i, col in enumerate(variables_quantitatives[:6]):  # Premi√®res 6 variables
    df[col].hist(bins=30, ax=axes[i])
    axes[i].set_title(f'Distribution de {col}')
    axes[i].set_xlabel(col)
    axes[i].set_ylabel('Fr√©quence')

plt.tight_layout()
plt.savefig('histogrammes_quanti_avec_outliers.png')
```

    Statistiques des variables quantitatives:
                                        mean        std    min     25%      50%  \
    conso_5_usages_ef               14443.94  572375.13  132.0  4341.7  6957.90   
    conso_5_usages_ef_energie_n1    13491.00  570719.26    1.0  4050.5  6414.65   
    cout_total_5_usages              1560.29   35667.75   38.3   598.9   879.60   
    hauteur_sous_plafond                2.61       4.29    0.2     2.5     2.50   
    cout_total_5_usages_energie_n1   1323.05   35316.31    0.0   492.3   733.60   
    surface_habitable_logement         92.11     323.88    1.0    45.0    62.90   
    
                                         75%          max  
    conso_5_usages_ef               11474.42  305858058.6  
    conso_5_usages_ef_energie_n1    10480.42  305142112.0  
    cout_total_5_usages              1255.50   18925018.0  
    hauteur_sous_plafond                2.50       2049.0  
    cout_total_5_usages_energie_n1   1077.03   18810120.0  
    surface_habitable_logement         77.60      19520.9  
    


    
![png](rapport_1_bis_files/rapport_1_bis_9_1.png)
    



```python
#Enlever les valeurs aberantes
seuils = {
        'hauteur_sous_plafond': (1.8, 4.0),
        'surface_habitable_logement': (15, 300),
        'conso_5_usages_ef': (500, 50_000),
        'conso_5_usages_ef_energie_n1': (500, 50_000),
        'cout_total_5_usages': (100, 20_000),
        'cout_total_5_usages_energie_n1': (100, 20_000)
    }
# Appliquer les seuils une colonne √† la fois
for col, (min_val, max_val) in seuils.items():
    if col in df.columns:
        # Cr√©er le masque pour CETTE colonne
        masque = (df[col] >= min_val) & (df[col] <= max_val)
        # Appliquer le masque sur tout le DataFrame
        df = df[masque]

print(f"Nettoyage termin√©. Shape final: {df.shape}")

# Statistiques descriptives
print("Statistiques des variables quantitatives:")
stats_quanti_sans_outliers = df[variables_quantitatives].describe().round(2).T.drop(columns=['count'])
print(stats_quanti_sans_outliers)
# Visualisation des distributions
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.ravel()

for i, col in enumerate(variables_quantitatives[:6]):  # Premi√®res 6 variables
    df[col].hist(bins=30, ax=axes[i])
    axes[i].set_title(f'Distribution de {col}')
    axes[i].set_xlabel(col)
    axes[i].set_ylabel('Fr√©quence')

plt.tight_layout()
plt.savefig('histogrammes_quanti_sans_outliers.png')
```

    Nettoyage termin√©. Shape final: (1110136, 30)
    Statistiques des variables quantitatives:
                                       mean      std    min     25%      50%  \
    conso_5_usages_ef               8527.54  5899.69  504.4  4344.5  6864.20   
    conso_5_usages_ef_energie_n1    7910.45  5539.21  519.0  4057.9  6346.05   
    cout_total_5_usages              978.85   567.25  114.0   598.0   870.30   
    hauteur_sous_plafond               2.58     0.22    1.8     2.5     2.50   
    cout_total_5_usages_energie_n1   839.96   534.03  100.0   493.4   726.70   
    surface_habitable_logement        62.65    26.52   15.0    45.0    62.30   
    
                                        75%      max  
    conso_5_usages_ef               11105.5  49988.4  
    conso_5_usages_ef_energie_n1    10177.1  49744.6  
    cout_total_5_usages              1225.0  10845.0  
    hauteur_sous_plafond                2.5      4.0  
    cout_total_5_usages_energie_n1   1050.7  10721.9  
    surface_habitable_logement         76.5    300.0  
    


    
![png](rapport_1_bis_files/rapport_1_bis_10_1.png)
    


## 2. Construction des mod√®les
### A. Mod√®les de r√©gression lin√©aire(pr√©vision consommation)
####  Variables retenues


On cherche ici √† construire un mod√®le permettant de pr√©voir la consommation √©nerg√©tique de l'utilisateur.

* Notre √©tude portant sur une zone se limitant √† un d√©partement, nous √©cartons les variables g√©ographiques dont l'influence est faible sur la cible : latitude et longitude .
* Il est important que les variables alors retenues n'aient pas une corr√©lation nulle avec la variable cible, la consommation.





```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from pathlib import Path


#On apporte les donn√©e 
df = pd.read_csv(r'C:/Users/marvi/Desktop/4_Python_ML/Projet_fin/donnees_ml_preparees.csv', sep=',')


#Variable a standardis√© 
Standardiser_Variables = ['hauteur_sous_plafond', 'surface_habitable_logement']

# Colonnes cat√©gorielles/bool√©ennes (d√©j√† encod√©es) √† utiliser telles quelles
Colonne_Utilises = [
    'qualite_isolation_murs', 'etiquette_dpe', 'periode_construction', 'nombre_appartement_cat', 'type_batiment_immeuble', 
    'type_batiment_maison', 'type_energie_principale_chauffage_Charbon', 'type_energie_principale_chauffage_Fioul', 
    'type_energie_principale_chauffage_Gaz (GPL/Propane/Butane)', 'type_energie_principale_chauffage_Gaz naturel', 
    'type_energie_principale_chauffage_R√©seau de chauffage urbain', 'type_energie_principale_chauffage_√âlectricit√©', 
    'type_energie_n1_Charbon', 'type_energie_n1_Fioul', 'type_energie_n1_Gaz (GPL/Propane/Butane)', 
    'type_energie_n1_Gaz naturel', 'type_energie_n1_R√©seau de chauffage urbain', 'type_energie_n1_√âlectricit√©', 'logement_neuf'
]

#√©viter multicolin√©arit√©
Exclure = ['conso_5_usages_ef_energie_n1','cout_total_5_usages','cout_total_5_usages_energie_n1']


Toutes_Donnees = Standardiser_Variables + Colonne_Utilises + ['conso_5_usages_ef']

# Matrice de corr√©lation
mat_corr = df[Toutes_Donnees].corr('pearson')

# Isolement de la colonne des corr√©lations  
corr_avec_score = mat_corr['conso_5_usages_ef'].sort_values(ascending=False)

# Supprimer 'conso_5_usages_ef' 
corr_avec_score = corr_avec_score.drop('conso_5_usages_ef')

# Graphique √† barres horizontal 
plt.figure(figsize=(12, 10)) 
corr_avec_score.plot(kind='barh', color=(corr_avec_score > 0).map({True: 'green', False: 'red'})) 
# La couleur est ajust√©e pour visualiser facilement les corr√©lations positives et n√©gatives

plt.title("Corr√©lation de chaque variable avec la variable cible 'conso_5_usages_ef'", fontsize=14)
plt.xlabel("Coefficient de corr√©lation de Pearson")
plt.ylabel("Variables")
plt.axvline(x=0, color='grey', linestyle='--') # Ligne de r√©f√©rence √† 0
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.tight_layout() # Assure que les √©tiquettes ne sont pas coup√©es
plt.show()
```


    
![png](rapport_1_bis_files/rapport_1_bis_12_0.png)
    


#### 1. R√©gression lin√©aire non p√©nalis√©e : pr√©vision de la consommation √©nerg√©tique

On effectue la r√©gression sur 10 runs avec une division entre train et test dans les proportions respectives de 80% et 20%, randomis√©e √† chaque run.
Les r√©sultats obtenus se trouvent ci-dessous :


```python
# --- Configuration et Donn√©es ---
Cible = 'conso_5_usages_ef'
RANDOM_SEED = 42
Run = 10

Toutes_Donnees = Standardiser_Variables + Colonne_Utilises 

# Convertir les bool√©ens en entiers (si ce n'est pas d√©j√† fait)
for col in df.columns:
    if df[col].dtype == 'bool':
        df[col] = df[col].astype(int)

# D√©finir les features (X) et la cible (y)
X = df.drop([Cible] + Exclure, axis=1, errors='ignore')
y = df[Cible]

# S'assurer que X ne contient que les colonnes n√©cessaires, dans le bon ordre
X = X[Toutes_Donnees]

print(f"Nombre total d'observations apr√®s chargement: {len(df)}")
print(f"Nombre de variables du mod√®le: {X.shape[1]}")

print("\nMod√®le : R√©gression Lin√©aire Standard")
print(f"√âvaluation de la stabilit√© du mod√®le sur {Run} splits al√©atoires (80/20)...")

stability_metrics = []

# Initialisation des transformateurs (ils seront fit_transform√© √† chaque it√©ration)
imputer = SimpleImputer(strategy='mean')
scaler = StandardScaler()
model = LinearRegression()

# === INITIALISATION DES VARIABLES POUR LE STOCKAGE DU DERNIER RUN (CRUCIAL) ===
y_test_run_last = None
y_pred_run_last = None
X_test_run_last = None # Ajout pour la Matrice de Confusion future

for i in range(1, Run + 1):
    
    # 1. Split des donn√©es
    X_train_run, X_test_run, y_train_run, y_test_run = train_test_split(
        X, y, test_size=0.3, random_state=RANDOM_SEED + i
    )
    
    # S√©parer les colonnes √† scaler
    X_train_scale = X_train_run[Standardiser_Variables]
    X_test_scale = X_test_run[Standardiser_Variables]
    
    # 2. Imputation 
    X_train_scale_imputed = imputer.fit_transform(X_train_scale)
    X_test_scale_imputed = imputer.transform(X_test_scale)
    
    # 3. Standardisation 
    X_train_scaled = scaler.fit_transform(X_train_scale_imputed)
    X_test_scaled = scaler.transform(X_test_scale_imputed)
    
    # 4. Reconstruction des ensembles (Concat√©ner les features standardis√©es et les features pass-through)
    
    # Features "Passthrough" (d√©j√† trait√©es/encod√©es)
    X_train_passthrough = X_train_run[Colonne_Utilises].values
    X_test_passthrough = X_test_run[Colonne_Utilises].values

    # Ensemble final pour l'entra√Ænement (Num√©rique Scal√© + Passthrough)
    X_train_final = np.hstack((X_train_scaled, X_train_passthrough))
    X_test_final = np.hstack((X_test_scaled, X_test_passthrough))

    # 5. Entra√Ænement et Pr√©diction du Mod√®le
    model.fit(X_train_final, y_train_run)
    y_pred_run = model.predict(X_test_final)

    # === SAUVEGARDE DU DERNIER RUN (Run 10) ===
    if i == Run:
        y_test_run_last = y_test_run
        y_pred_run_last = y_pred_run
        X_test_run_last = X_test_run
    
    # 6. Calcul des M√©triques
    mse = mean_squared_error(y_test_run, y_pred_run)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test_run, y_pred_run)
    
    stability_metrics.append({'run': i, 'R2': r2, 'RMSE': rmse})
    print(f"Run {i}/{Run}: R2={r2:.4f}, RMSE={rmse:.2f}")
```

    Nombre total d'observations apr√®s chargement: 1043068
    Nombre de variables du mod√®le: 21
    
    Mod√®le : R√©gression Lin√©aire Standard
    √âvaluation de la stabilit√© du mod√®le sur 10 splits al√©atoires (80/20)...
    Run 1/10: R2=0.7786, RMSE=2798.53
    Run 2/10: R2=0.7803, RMSE=2786.73
    Run 3/10: R2=0.7778, RMSE=2798.76
    Run 4/10: R2=0.7808, RMSE=2780.48
    Run 5/10: R2=0.7794, RMSE=2788.00
    Run 6/10: R2=0.7779, RMSE=2790.84
    Run 7/10: R2=0.7782, RMSE=2798.60
    Run 8/10: R2=0.7785, RMSE=2788.28
    Run 9/10: R2=0.7788, RMSE=2783.82
    Run 10/10: R2=0.7782, RMSE=2797.28
    


```python
results_df = pd.DataFrame(stability_metrics)

print("\n" + "="*54)
print("R√âSUM√â DE LA STABILIT√â DU MOD√àLE (R√©gression Lin√©aire)")
print("="*54)
print(f"Meilleur R2 : {results_df['R2'].max():.4f}")
print(f"Pire R2   : {results_df['R2'].min():.4f}")
print(f"R2 Moyen  : {results_df['R2'].mean():.4f}")
print(f"√âcart Type R2 : {results_df['R2'].std():.4f}")



feature_names = Standardiser_Variables + Colonne_Utilises
coefficients = model.coef_

# Si vous avez plusieurs variables cibles (r√©gression multi-sorties),
# model.coef_ sera un tableau 2D. Il faut s'assurer qu'il est aplati (flattened).
# S'il est 1D (r√©gression simple), l'aplatissement ne change rien.
if coefficients.ndim > 1:
    coefficients = coefficients.flatten()
    
# 2. Cr√©er le DataFrame
coefficients_df = pd.DataFrame({
    'Variable': feature_names,
    'Coefficient': coefficients
})

# 3. Trier et afficher (optionnel, mais recommand√©)
# Trie les variables par la valeur absolue du coefficient pour voir les plus importantes
coefficients_df['Importance_Absolue'] = np.abs(coefficients_df['Coefficient'])
coefficients_df = coefficients_df.sort_values(by='Importance_Absolue', ascending=False)

# Affichage final
print("\n" + "="*39)
print("COEFFICIENTS DU DERNIER MOD√àLE ENTRAINE")
print("="*39)
print(coefficients_df.to_string(index=False, float_format="%.4f"))
```

    
    ======================================================
    R√âSUM√â DE LA STABILIT√â DU MOD√àLE (R√©gression Lin√©aire)
    ======================================================
    Meilleur R2 : 0.7808
    Pire R2   : 0.7778
    R2 Moyen  : 0.7788
    √âcart Type R2 : 0.0010
    
    =======================================
    COEFFICIENTS DU DERNIER MOD√àLE ENTRAINE
    =======================================
                                                        Variable  Coefficient  Importance_Absolue
                                          type_batiment_immeuble   10406.8179          10406.8179
                                     type_energie_n1_√âlectricit√©   -5154.8270           5154.8270
                                         type_energie_n1_Charbon    4527.7597           4527.7597
                                      surface_habitable_logement    3328.1414           3328.1414
                                                   etiquette_dpe   -2806.1083           2806.1083
                                            type_batiment_maison   -2013.8749           2013.8749
                       type_energie_principale_chauffage_Charbon   -1660.5466           1660.5466
                         type_energie_principale_chauffage_Fioul    1376.7527           1376.7527
                                     type_energie_n1_Gaz naturel   -1361.4987           1361.4987
                      type_energie_n1_R√©seau de chauffage urbain   -1315.6033           1315.6033
                                           type_energie_n1_Fioul   -1110.3532           1110.3532
      type_energie_principale_chauffage_Gaz (GPL/Propane/Butane)    -815.7459            815.7459
    type_energie_principale_chauffage_R√©seau de chauffage urbain     757.2085            757.2085
                        type_energie_n1_Gaz (GPL/Propane/Butane)    -756.9495            756.9495
                   type_energie_principale_chauffage_√âlectricit√©    -605.9483            605.9483
                                          qualite_isolation_murs    -515.7051            515.7051
                                                   logement_neuf    -215.6440            215.6440
                                          nombre_appartement_cat    -186.8802            186.8802
                   type_energie_principale_chauffage_Gaz naturel    -137.1896            137.1896
                                            periode_construction    -124.9462            124.9462
                                            hauteur_sous_plafond     -23.1531             23.1531
    


```python
import matplotlib.pyplot as plt
import numpy as np

plt.figure(figsize=(12, 6))
plt.scatter(y_test_run_last, y_pred_run_last, alpha=0.5)

# Ligne de r√©f√©rence y=x (o√π les pr√©dictions parfaites devraient se trouver)
# D√©termination des limites des axes pour s'assurer que la ligne rouge est visible
max_val = max(y_test_run_last.max(), y_pred_run_last.max())
min_val = min(y_test_run_last.min(), y_pred_run_last.min())
plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Ligne d\'ajustement parfait')

plt.title('V√©rification de l\'ajustement : Consommation R√©elle vs. Pr√©dite (Run 10)', fontsize=14)
plt.xlabel(f'Consommation R√©elle ({Cible})', fontsize=12)
plt.ylabel(f'Consommation Pr√©dite', fontsize=12)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.6)
plt.show()
```


    
![png](rapport_1_bis_files/rapport_1_bis_17_0.png)
    


Les scores obtenus par la r√©gression sont satisfaisants avec une valeur moyenne de R2 √©gale √† 0.7788. Autrement dit, la variabilit√© de la consommation √©nerg√©tique est expliqu√©e √† 77.88% par les variables utilis√©es.
Toutefois, nous avons effectu√© une r√©gression p√©nalis√©e afin d'√©ventuellement obtenir de meilleurs r√©sultats.

#### 2. R√©gression lin√©aire r√©gularis√©e


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from pathlib import Path

# D√©finir les features (X) et la cible (y)
X = df.drop([Cible] + Exclure, axis=1, errors='ignore')
y = df[Cible]
# ====================================================================
# Split Initial & Pr√©traitement de Base (Pr√©paration GridSearch)
# ====================================================================

print("\n--- Pr√©traitement et Split initial pour GridSearch ---")

# Split initial (80% Train, 20% Test)
# X et y doivent avoir √©t√© d√©finis dans la CELL 2
X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(
    X, y, test_size=0.3, random_state=RANDOM_SEED
)

# Nous utiliserons y_train_raw comme cible pour le GridSearch sur les donn√©es brutes
y_target_gs = y_train_raw


# --- 1. Imputation (Fit sur Train) ---
imputer_gs = SimpleImputer(strategy='mean')
# Imputer toutes les colonnes √† standardiser
X_train_imputed = imputer_gs.fit_transform(X_train_raw[Standardiser_Variables])

# --- 2. Standardisation (Fit sur Train) ---
scaler_gs = StandardScaler()
# Standardiser les colonnes imput√©es
X_train_scaled = scaler_gs.fit_transform(X_train_imputed)

# --- 3. Reconstruction de la Matrice d'Entra√Ænement ---
# Colonnes Passthrough (d√©j√† encod√©es)
X_train_passthrough = X_train_raw[Colonne_Utilises].values

# X_train_final sera la matrice d'entra√Ænement pr√©trait√©e pour le GridSearch
X_train_final = np.hstack((X_train_scaled, X_train_passthrough))

print(f"Taille du jeu d'entra√Ænement final (pour GridSearch): {X_train_final.shape}")
```

    
    --- Pr√©traitement et Split initial pour GridSearch ---
    Taille du jeu d'entra√Ænement final (pour GridSearch): (730147, 21)
    


Nous avons commenc√© par chercher la meilleure valeur du coefficient de r√©gularisation alpha parmi les valeurs suivantes : 0.0, 0.1, 1.0, 10.0, 100.0, 500.0, 1000.0 pour Ridge et Lasso.



```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# Import des mod√®les de r√©gression r√©gularis√©e
from sklearn.linear_model import Ridge, Lasso, LinearRegression 
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer

# ====================================================================
# CELL 4: GridSearch pour Ridge et Lasso (Recherche de alpha)
# ====================================================================

print("\n--- GridSearch pour optimiser Ridge et Lasso (Cible Brute) ---")
param_grid = {'alpha': [0.0, 0.1, 1.0, 10.0, 100.0, 500.0, 1000.0]} 


y_target_gs = y_train_raw #

best_model = None
best_score = -np.inf 
best_name = ""

# A. GridSearch pour Ridge
ridge_model = Ridge(random_state=RANDOM_SEED)
# Utiliser n_jobs=1 pour √©viter le MemoryError que vous avez rencontr√©
grid_ridge = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=1, verbose=1)
grid_ridge.fit(X_train_final, y_target_gs)

print("\nR√©sultat Ridge:")
print(f"Meilleur alpha pour Ridge: {grid_ridge.best_params_['alpha']:.4f}")

if grid_ridge.best_score_ > best_score:
    best_score = grid_ridge.best_score_
    best_model = grid_ridge.best_estimator_
    best_name = "Ridge"


```

    
    --- GridSearch pour optimiser Ridge et Lasso (Cible Brute) ---
    Fitting 5 folds for each of 7 candidates, totalling 35 fits
    
    R√©sultat Ridge:
    Meilleur alpha pour Ridge: 10.0000
    


```python
Le mod√®le Lasso ayant rencontr√© des probl√®mes de convergence, nous avons retenu le mod√®le Ridge avec alpha = 10.
Afin de tester la stabilit√© du mod√®le, on effectue la r√©gression sur 10 runs avec une division entre train et test dans les proportions respectives de 80% et 20%, randomis√©e √† chaque run.
Les r√©sultats obtenus se trouvent ci-dessous :
```


```python
# ==============================================
# Test de Stabilit√© (Validation Crois√©e 10 Runs)
# ==============================================


# --- Configuration et Donn√©es ---
Cible = 'conso_5_usages_ef'
RANDOM_SEED = 42
Run = 10

# üö® D√âFINITION  MEILLEUR MOD√àLE (Bas√© sur le GridSearch et Ridge)


from sklearn.linear_model import Ridge
best_model_name = "Ridge"
best_model = Ridge(alpha=10.0, random_state=RANDOM_SEED)


print(f"\n--- Test de Stabilit√© pour le meilleur mod√®le ({best_model_name}, alpha=10.0) ---")
print(f"√âvaluation sur {Run} splits al√©atoires (30% test)...")

stability_metrics = []

# R√©initialiser les transformateurs
imputer_stab = SimpleImputer(strategy='mean')
scaler_stab = StandardScaler()

# Initialisation des variables pour le stockage du dernier run (Crucial)
y_test_run_last = None
y_pred_run_last = None
X_test_run_last = None

for i in range(1, Run + 1):
    
    # 1. Split des donn√©es 
    X_train_stab, X_test_stab, y_train_stab, y_test_stab = train_test_split(
        X, y, test_size=0.2, random_state=RANDOM_SEED + i
    )
    
    # Pr√©traitement complet du nouveau split
    X_train_scale_stab = X_train_stab[Standardiser_Variables]
    X_test_scale_stab = X_test_stab[Standardiser_Variables]
    
    # Imputation et Standardisation
    imputer_stab.fit(X_train_scale_stab)
    X_train_imputed_stab = imputer_stab.transform(X_train_scale_stab)
    X_test_imputed_stab = imputer_stab.transform(X_test_scale_stab)

    scaler_stab.fit(X_train_imputed_stab)
    X_train_scaled_stab = scaler_stab.transform(X_train_imputed_stab)
    X_test_scaled_stab = scaler_stab.transform(X_test_imputed_stab)
    
    # Reconstruction des ensembles
    X_train_final_stab = np.hstack((X_train_scaled_stab, X_train_stab[Colonne_Utilises].values))
    X_test_final_stab = np.hstack((X_test_scaled_stab, X_test_stab[Colonne_Utilises].values))

    # 4. Entra√Ænement et Pr√©diction (Cible Brute)
    best_model.fit(X_train_final_stab, y_train_stab)
    y_pred_run_stab = best_model.predict(X_test_final_stab)
    
    # 5. Stockage du Dernier Run
    if i == Run:
        y_test_run_last = y_test_stab
        y_pred_run_last = y_pred_run_stab
        X_test_run_last = X_test_stab
    
    # 6. Calcul des M√©triques
    mse = mean_squared_error(y_test_stab, y_pred_run_stab)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test_stab, y_pred_run_stab)
    
    stability_metrics.append({'run': i, 'R2': r2, 'RMSE': rmse})
    print(f"Run {i}/{Run}: R2={r2:.4f}, RMSE={rmse:.2f}")

```

    
    --- Test de Stabilit√© pour le meilleur mod√®le (Ridge, alpha=10.0) ---
    √âvaluation sur 10 splits al√©atoires (30% test)...
    Run 1/10: R2=0.7784, RMSE=2789.76
    Run 2/10: R2=0.7811, RMSE=2778.23
    Run 3/10: R2=0.7796, RMSE=2799.31
    Run 4/10: R2=0.7811, RMSE=2770.94
    Run 5/10: R2=0.7791, RMSE=2784.33
    Run 6/10: R2=0.7785, RMSE=2788.41
    Run 7/10: R2=0.7795, RMSE=2789.69
    Run 8/10: R2=0.7792, RMSE=2790.82
    Run 9/10: R2=0.7788, RMSE=2784.00
    Run 10/10: R2=0.7793, RMSE=2794.16
    


```python
results_df = pd.DataFrame(stability_metrics)
print("\n" + "="*54)
print("R√âSUM√â DE LA STABILIT√â DU MOD√àLE (R√©gression Lin√©aire)")
print("="*54)
print(f"Meilleur R2 : {results_df['R2'].max():.4f}")
print(f"Pire R2   : {results_df['R2'].min():.4f}")
print(f"R2 Moyen  : {results_df['R2'].mean():.4f}")
print(f"√âcart Type R2 : {results_df['R2'].std():.4f}")
```

    
    ======================================================
    R√âSUM√â DE LA STABILIT√â DU MOD√àLE (R√©gression Lin√©aire)
    ======================================================
    Meilleur R2 : 0.7811
    Pire R2   : 0.7784
    R2 Moyen  : 0.7795
    √âcart Type R2 : 0.0009
    

### B. Mod√®le de classification : pr√©vision de l'√©tiquette DPE


```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score

# -----------------------------
# 1Ô∏è‚É£ Chargement du dataset
# -----------------------------
df = pd.read_csv(r'C:\Users\marvi\Desktop\4_Python_ML\Projet\donnees_ml_preparees.csv',sep=',')
df.columns = df.columns.str.strip().str.lower()

y = df['etiquette_dpe']
X = df.drop(columns=['etiquette_dpe'])

# -----------------------------
# 2Ô∏è‚É£ Split complet train/test
# -----------------------------
X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# -----------------------------
# 3Ô∏è‚É£ Sous-√©chantillon stratifi√©
# -----------------------------
sample_train_size = 5000
sample_test_size = 1000

X_train, _, y_train, _ = train_test_split(
    X_train_full, y_train_full,
    train_size=sample_train_size,
    stratify=y_train_full,
    random_state=42
)

X_test, _, y_test, _ = train_test_split(
    X_test_full, y_test_full,
    train_size=sample_test_size,
    stratify=y_test_full,
    random_state=42
)

# -----------------------------
# 4Ô∏è‚É£ Standardisation
# -----------------------------
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# -----------------------------
# 5Ô∏è‚É£ RandomizedSearchCV pour hyperparam√®tres
# -----------------------------
param_dist = {
    'C': [0.01, 0.1, 1, 10],
    'penalty': ['l1', 'l2']
}

logreg = LogisticRegression(solver='saga', max_iter=5000, random_state=42)

random_search = RandomizedSearchCV(
    estimator=logreg,
    param_distributions=param_dist,
    n_iter=5,
    scoring='f1_weighted',
    cv=2,
    n_jobs=1,
    verbose=1,
    random_state=42
)

random_search.fit(X_train_scaled, y_train)

best_params = random_search.best_params_
print("Les meilleurs param√®tres sont :", best_params)
```

    Fitting 2 folds for each of 5 candidates, totalling 10 fits
    Les meilleurs param√®tres sont : {'penalty': 'l2', 'C': 10}
    


```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score
from sklearn.preprocessing import StandardScaler

n_runs=10


print("\nMod√®le : R√©gression Logistique")
print(f"√âvaluation de la stabilit√© du mod√®le sur {n_runs} avec des √©chantillons stratifi√©s d'entra√Ænement de tailles respectives {sample_train_size} et {sample_test_size}")


print(f"Nombre total d'observations apr√®s chargement: {len(df)}")
print(f"Nombre de variables du mod√®le: {X.shape[1]}")

# -----------------------------
# 1Ô∏è‚É£ Chargement du dataset
# -----------------------------
df = pd.read_csv(r'C:\Users\marvi\Desktop\4_Python_ML\Projet\donnees_ml_preparees.csv',sep=',')
df.columns = df.columns.str.strip().str.lower()

X = df.drop(columns=['etiquette_dpe'])
y = df['etiquette_dpe']

# -----------------------------
# 2Ô∏è‚É£ Split complet train/test
# -----------------------------
X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# -----------------------------
# 3Ô∏è‚É£ Sous-√©chantillon stratifi√©
# -----------------------------
sample_train_size = 10000
sample_test_size = 3000

X_train, _, y_train, _ = train_test_split(
    X_train_full, y_train_full,
    train_size=sample_train_size,
    stratify=y_train_full,
    random_state=42
)

X_test, _, y_test, _ = train_test_split(
    X_test_full, y_test_full,
    train_size=sample_test_size,
    stratify=y_test_full,
    random_state=42
)

# -----------------------------
# 4Ô∏è‚É£ Standardisation
# -----------------------------
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# -----------------------------
# 5Ô∏è‚É£ Hyperparam√®tres (√† adapter)
# -----------------------------
best_params = {'C': 10, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 5000}

# -----------------------------
# 6Ô∏è‚É£ Entra√Ænement sur 10 runs
# -----------------------------
n_runs = 10
scores = []

print("Entra√Ænement sur 10 runs\n")

for i in range(n_runs):
    model = LogisticRegression(**best_params, random_state=i, n_jobs=1)
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    f1 = f1_score(y_test, y_pred, average='weighted')
    scores.append(f1)
    print(f"Run {i+1:2d}: F1-score = {f1:.4f}")

mean_f1 = np.mean(scores)
std_f1 = np.std(scores)







print("\n Moyenne des F1-scores :", round(mean_f1, 4))
print(" √âcart-type :", round(std_f1, 4))


```

    
    Mod√®le : R√©gression Logistique
    √âvaluation de la stabilit√© du mod√®le sur 10 avec des √©chantillons stratifi√©s d'entra√Ænement de tailles respectives 5000 et 1000
    Nombre total d'observations apr√®s chargement: 1043068
    Nombre de variables du mod√®le: 28
    Entra√Ænement sur 10 runs
    
    Run  1: F1-score = 0.7798
    Run  2: F1-score = 0.7798
    Run  3: F1-score = 0.7798
    Run  4: F1-score = 0.7798
    Run  5: F1-score = 0.7798
    Run  6: F1-score = 0.7798
    Run  7: F1-score = 0.7798
    Run  8: F1-score = 0.7798
    Run  9: F1-score = 0.7798
    Run 10: F1-score = 0.7798
    
     Moyenne des F1-scores : 0.7798
     √âcart-type : 0.0
    
